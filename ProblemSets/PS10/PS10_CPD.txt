\documentclass{article} \usepackage[utf8]{inputenc} \title{PS10} 
\author{christopher.p.danko-1 } \date{April 2020} \begin{document} 
\maketitle \section{Model evaluation} Model evaluation:\\ Tree model\\ 
Sensitivity: .9461\\ Specificity: .5888\\ Accuracy: .8606\\ \\ Logit 
model\\ Sensitivity: .9568\\ Specificity: .4804\\ Accuracy: .8428\\ \\ 
Neural net model\\ Sensitivity: .9354\\ Specificity: .6055\\ Accuracy: 
.8564\\ \\ Naive Bayes\\ Sensitivity: .8991\\ Specificity: .5997\\ 
Accuracy: .8274\\ \\ KNN\\ Accuracy: .8454\\ Sensitivity: .9243\\ 
Specificity: .5946\\ \\ SVM\\ Accuracy: .8557\\ Sensitivity: .9425\\ 
Specificity: .5799\\ \\ Of the models tested, the tree model had the 
highest accuracy. The logit model had the highest sensitivity, and the 
neural net model has the highest specificity. Thus, if we wanted a model 
that created the least amount of false positives, we should use the 
neural net. If we wanted a model that created the least amount of false 
positves, we should use the logit. If false positives and false 
negatives are equally bad in our data, we should opt for the tree. I 
will also note that the neural net appeared to have the best tradeoff of 
the three measures. \begin{table}[h!]
  \begin{center}
    \caption{Model Parameters}
    \label{tab:table1}
    \begin{tabular}{l|c|r|l}
      \textbf{Model} & \textbf{Parameter 1} & \textbf{Parameter 2} & 
\textbf{Parameter 3}\\
      \hline
      & minsplit & minbucket & cp\\
      Tree & 11 & 18 & .00542\\
      \hline
      &$\lambda$ & $\alpha$ &\\
      Logit & 1.37 & .196 & NA\\
      \hline
      & Size & Decay & Max Iterations\\
      Neural Net & 10 & .487 & 1000\\
      \hline
      & K & &\\
      KNN & 29 & &\\
      \hline
      & kernel & cost & $\gamma$\\
      SVM & radial & 1 & .5
    \end{tabular}
  \end{center}
\end{table}
